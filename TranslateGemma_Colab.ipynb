{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸŒ TranslateGemma 12B - Dá»‹ch thuáº­t AI\n",
        "\n",
        "Model dá»‹ch thuáº­t máº¡nh máº½ cá»§a Google há»— trá»£ 55 ngÃ´n ngá»¯\n",
        "\n",
        "**LÆ°u Ã½:** Chá»n GPU runtime (Runtime > Change runtime type > T4 GPU)"
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“¦ BÆ°á»›c 1: CÃ i Ä‘áº·t thÆ° viá»‡n"
      ],
      "metadata": {
        "id": "install"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers>=4.46.0 torch pillow accelerate sentencepiece protobuf\n",
        "print(\"âœ… ÄÃ£ cÃ i Ä‘áº·t xong!\")"
      ],
      "metadata": {
        "id": "install_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ”„ BÆ°á»›c 2: Load model (cháº¡y 1 láº§n, máº¥t ~1-2 phÃºt)"
      ],
      "metadata": {
        "id": "load"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForImageTextToText, AutoProcessor\n",
        "\n",
        "print(\"ğŸ”„ Äang load TranslateGemma 12B...\")\n",
        "print(\"â³ Vui lÃ²ng Ä‘á»£i 1-2 phÃºt...\")\n",
        "\n",
        "model_id = \"google/translategemma-12b-it\"\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = AutoModelForImageTextToText.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "print(\"âœ… Model 12B Ä‘Ã£ load xong! Sáºµn sÃ ng dá»‹ch thuáº­t.\")"
      ],
      "metadata": {
        "id": "load_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ› ï¸ BÆ°á»›c 3: HÃ m dá»‹ch thuáº­t"
      ],
      "metadata": {
        "id": "function"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_text(text, source_lang=\"vi\", target_lang=\"en\", max_tokens=200):\n",
        "    \"\"\"\n",
        "    Dá»‹ch vÄƒn báº£n\n",
        "    \n",
        "    Args:\n",
        "        text: VÄƒn báº£n cáº§n dá»‹ch\n",
        "        source_lang: MÃ£ ngÃ´n ngá»¯ nguá»“n (vi, en, zh, ja, ko, fr, de, es, th, id, cs...)\n",
        "        target_lang: MÃ£ ngÃ´n ngá»¯ Ä‘Ã­ch\n",
        "        max_tokens: Sá»‘ token tá»‘i Ä‘a cho output\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"source_lang_code\": source_lang,\n",
        "                    \"target_lang_code\": target_lang,\n",
        "                    \"text\": text,\n",
        "                }\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    inputs = processor.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device, dtype=torch.bfloat16)\n",
        "    \n",
        "    input_len = len(inputs['input_ids'][0])\n",
        "    \n",
        "    with torch.inference_mode():\n",
        "        generation = model.generate(\n",
        "            **inputs,\n",
        "            do_sample=False,\n",
        "            max_new_tokens=max_tokens\n",
        "        )\n",
        "    \n",
        "    generation = generation[0][input_len:]\n",
        "    translated = processor.decode(generation, skip_special_tokens=True)\n",
        "    \n",
        "    return translated\n",
        "\n",
        "\n",
        "def translate_image(image_url, source_lang=\"en\", target_lang=\"vi\", max_tokens=200):\n",
        "    \"\"\"\n",
        "    TrÃ­ch xuáº¥t vÃ  dá»‹ch text tá»« áº£nh\n",
        "    \n",
        "    Args:\n",
        "        image_url: URL cá»§a áº£nh\n",
        "        source_lang: MÃ£ ngÃ´n ngá»¯ nguá»“n\n",
        "        target_lang: MÃ£ ngÃ´n ngá»¯ Ä‘Ã­ch\n",
        "        max_tokens: Sá»‘ token tá»‘i Ä‘a cho output\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"image\",\n",
        "                    \"source_lang_code\": source_lang,\n",
        "                    \"target_lang_code\": target_lang,\n",
        "                    \"url\": image_url,\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    inputs = processor.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device, dtype=torch.bfloat16)\n",
        "    \n",
        "    input_len = len(inputs['input_ids'][0])\n",
        "    \n",
        "    with torch.inference_mode():\n",
        "        generation = model.generate(\n",
        "            **inputs,\n",
        "            do_sample=False,\n",
        "            max_new_tokens=max_tokens\n",
        "        )\n",
        "    \n",
        "    generation = generation[0][input_len:]\n",
        "    translated = processor.decode(generation, skip_special_tokens=True)\n",
        "    \n",
        "    return translated\n",
        "\n",
        "print(\"âœ… HÃ m dá»‹ch thuáº­t Ä‘Ã£ sáºµn sÃ ng!\")"
      ],
      "metadata": {
        "id": "function_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ§ª BÆ°á»›c 4: Test dá»‹ch thuáº­t\n",
        "\n",
        "### Dá»‹ch vÄƒn báº£n"
      ],
      "metadata": {
        "id": "test"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1: Tiáº¿ng Viá»‡t -> Tiáº¿ng Anh\n",
        "text_vi = \"Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI. HÃ´m nay trá»i Ä‘áº¹p quÃ¡!\"\n",
        "print(f\"ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t: {text_vi}\")\n",
        "\n",
        "result = translate_text(text_vi, source_lang=\"vi\", target_lang=\"en\")\n",
        "print(f\"ğŸ‡ºğŸ‡¸ Tiáº¿ng Anh: {result}\")"
      ],
      "metadata": {
        "id": "test1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2: Tiáº¿ng Anh -> Tiáº¿ng Viá»‡t\n",
        "text_en = \"Hello! I am an AI assistant. The weather is beautiful today!\"\n",
        "print(f\"ğŸ‡ºğŸ‡¸ Tiáº¿ng Anh: {text_en}\")\n",
        "\n",
        "result = translate_text(text_en, source_lang=\"en\", target_lang=\"vi\")\n",
        "print(f\"ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t: {result}\")"
      ],
      "metadata": {
        "id": "test2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 3: Tiáº¿ng Viá»‡t -> Tiáº¿ng Trung\n",
        "text_vi = \"TÃ´i yÃªu há»c tiáº¿ng Trung. NÃ³ ráº¥t thÃº vá»‹!\"\n",
        "print(f\"ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t: {text_vi}\")\n",
        "\n",
        "result = translate_text(text_vi, source_lang=\"vi\", target_lang=\"zh\")\n",
        "print(f\"ğŸ‡¨ğŸ‡³ Tiáº¿ng Trung: {result}\")"
      ],
      "metadata": {
        "id": "test3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dá»‹ch tá»« áº£nh"
      ],
      "metadata": {
        "id": "test_image"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 4: TrÃ­ch xuáº¥t vÃ  dá»‹ch text tá»« áº£nh\n",
        "image_url = \"https://c7.alamy.com/comp/2YAX36N/traffic-signs-in-czech-republic-pedestrian-zone-2YAX36N.jpg\"\n",
        "print(f\"ğŸ–¼ï¸  áº¢nh: {image_url}\")\n",
        "\n",
        "result = translate_image(image_url, source_lang=\"cs\", target_lang=\"vi\")\n",
        "print(f\"ğŸ‡»ğŸ‡³ Dá»‹ch sang Tiáº¿ng Viá»‡t: {result}\")"
      ],
      "metadata": {
        "id": "test4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¯ BÆ°á»›c 5: Dá»‹ch vÄƒn báº£n cá»§a báº¡n\n",
        "\n",
        "Thay Ä‘á»•i text vÃ  ngÃ´n ngá»¯ theo Ã½ muá»‘n!"
      ],
      "metadata": {
        "id": "custom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nháº­p vÄƒn báº£n cá»§a báº¡n\n",
        "my_text = \"HÃ´m nay tÃ´i há»c láº­p trÃ¬nh Python\"  # Thay Ä‘á»•i text nÃ y\n",
        "source = \"vi\"  # NgÃ´n ngá»¯ nguá»“n\n",
        "target = \"en\"  # NgÃ´n ngá»¯ Ä‘Ã­ch\n",
        "\n",
        "print(f\"ğŸ“ Input ({source}): {my_text}\")\n",
        "result = translate_text(my_text, source_lang=source, target_lang=target)\n",
        "print(f\"âœ… Output ({target}): {result}\")"
      ],
      "metadata": {
        "id": "custom_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“š NgÃ´n ngá»¯ Ä‘Æ°á»£c há»— trá»£\n",
        "\n",
        "TranslateGemma há»— trá»£ 55 ngÃ´n ngá»¯. Má»™t sá»‘ mÃ£ phá»• biáº¿n:\n",
        "\n",
        "- `vi` - Tiáº¿ng Viá»‡t ğŸ‡»ğŸ‡³\n",
        "- `en` - Tiáº¿ng Anh ğŸ‡ºğŸ‡¸\n",
        "- `zh` - Tiáº¿ng Trung ğŸ‡¨ğŸ‡³\n",
        "- `ja` - Tiáº¿ng Nháº­t ğŸ‡¯ğŸ‡µ\n",
        "- `ko` - Tiáº¿ng HÃ n ğŸ‡°ğŸ‡·\n",
        "- `fr` - Tiáº¿ng PhÃ¡p ğŸ‡«ğŸ‡·\n",
        "- `de` - Tiáº¿ng Äá»©c ğŸ‡©ğŸ‡ª\n",
        "- `es` - Tiáº¿ng TÃ¢y Ban Nha ğŸ‡ªğŸ‡¸\n",
        "- `th` - Tiáº¿ng ThÃ¡i ğŸ‡¹ğŸ‡­\n",
        "- `id` - Tiáº¿ng Indonesia ğŸ‡®ğŸ‡©\n",
        "- `cs` - Tiáº¿ng SÃ©c ğŸ‡¨ğŸ‡¿\n",
        "- `ru` - Tiáº¿ng Nga ğŸ‡·ğŸ‡º\n",
        "- `ar` - Tiáº¿ng áº¢ Ráº­p ğŸ‡¸ğŸ‡¦\n",
        "- `pt` - Tiáº¿ng Bá»“ ÄÃ o Nha ğŸ‡µğŸ‡¹\n",
        "- `it` - Tiáº¿ng Ã ğŸ‡®ğŸ‡¹\n",
        "\n",
        "VÃ  nhiá»u ngÃ´n ngá»¯ khÃ¡c!"
      ],
      "metadata": {
        "id": "languages"
      }
    }
  ]
}
